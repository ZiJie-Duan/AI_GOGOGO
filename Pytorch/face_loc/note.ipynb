{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fc06e77-3983-4f33-9050-d5edbb55bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8204a968-0a5f-4d60-b814-e3c48a0e7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "from frame import FLCDataset, visualize_transformed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81167968-7b8a-4c8c-9af7-f631e7dfd845",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_INPUT_SIZE = [12,12]\n",
    "\n",
    "# 定义转换操作\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_INPUT_SIZE[0]),\n",
    "    transforms.CenterCrop(IMG_INPUT_SIZE[0]),\n",
    "    transforms.ToTensor(),  # 将PIL图像或NumPy ndarray转换为FloatTensor。\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # 标准化，使用ImageNet的均值和标准差\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def label_transform(label, img_size):\n",
    "    # 目标尺寸\n",
    "    nh, nw = IMG_INPUT_SIZE[1], IMG_INPUT_SIZE[0]\n",
    "    # 原始尺寸\n",
    "    h, w = img_size\n",
    "    # 计算缩放比例\n",
    "    x_scale = nw / w\n",
    "    y_scale = nh / h\n",
    "    \n",
    "    # 处理标签中的每个坐标\n",
    "    transformed_label = []\n",
    "    for i, value in enumerate(label):\n",
    "        if i % 2 == 0:  # 偶数索引位置，x坐标\n",
    "            transformed_label.append(value * x_scale)\n",
    "        else:  # 奇数索引位置，y坐标\n",
    "            transformed_label.append(value * y_scale)\n",
    "            \n",
    "    return transformed_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce958c5d-85fa-48b9-92aa-c9a3c73587fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FLCDataset(r\"C:\\Users\\lucyc\\Desktop\\face_loc\\train.csv\", r\"C:\\Users\\lucyc\\Desktop\\face_loc\\train\", transform, label_transform)\n",
    "val_dataset = FLCDataset(r\"C:\\Users\\lucyc\\Desktop\\face_loc\\val.csv\", r\"C:\\Users\\lucyc\\Desktop\\face_loc\\val\", transform, label_transform)\n",
    "test_dataset = FLCDataset(r\"C:\\Users\\lucyc\\Desktop\\face_loc\\test.csv\", r\"C:\\Users\\lucyc\\Desktop\\face_loc\\test\", transform, label_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431509f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d58eb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 12, 12])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf0aeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,  -4.7664,   8.4112,  12.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  4.3960,   3.6832,   8.0792,   3.5644,   7.1287,   6.7723,   4.6337,\n",
       "           9.1485,   7.8416,   8.9109],\n",
       "        [  2.3784,   3.6757,   6.0541,   3.4595,   4.7568,   5.9459,   2.4865,\n",
       "           8.3243,   5.6216,   8.3243],\n",
       "        [ 13.3538,   0.0000,   8.8615,  12.3077,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  2.4375,   3.7500,   6.1875,   4.0312,   3.9375,   6.5625,   2.6250,\n",
       "           7.5000,   6.2812,   7.6875],\n",
       "        [  0.0000,  -0.5647,  11.4353,  11.7176,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  4.2000,   5.1600,   8.2800,   5.2800,   5.0400,   8.0400,   5.0400,\n",
       "          10.2000,   7.6800,  10.6800],\n",
       "        [  0.0000,   1.2000,  11.1000,  12.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,  10.5000,  12.3871,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  2.5043,   3.7565,   6.2609,   3.8609,   4.5913,   6.2609,   2.8174,\n",
       "           8.2435,   6.1565,   8.2435],\n",
       "        [ 67.6000,  68.4000,  11.6000,  16.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  2.4762,   4.9524,   6.2857,   5.0476,   4.5714,   5.9048,   2.9524,\n",
       "           8.6667,   6.0000,   8.8571],\n",
       "        [  0.0000,   1.9636,  10.9091,  12.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   1.8824,  10.8235,  12.2353,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   1.4118,   8.4706,  12.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  2.6667,  -1.3333,   9.0000,  12.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [ -3.1111,   3.5556,   9.5556,  12.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  7.1250,   0.0000,  13.5000,  15.3750,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,  -6.0000,  15.0000,  15.6000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   3.9292,   8.2832,  11.8938,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  2.3333,   0.0000,  10.0000,  12.8333,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   9.4545,  10.5455,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [ -3.9130,   0.0000,  11.2174,  12.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [ 26.8966, -69.1034,  11.1724,  10.7586,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [ -1.4694,   0.0000,   6.6122,  10.0408,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [ -1.1250,   2.2500,  12.0000,   9.3750,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  2.5487,   3.0796,   6.3717,   3.1858,   4.5664,   4.9912,   2.8673,\n",
       "           7.6460,   6.2655,   7.7522],\n",
       "        [  0.0000,  -4.9756,   8.6341,  10.9756,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.3871,  10.7097,  12.1290,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000],\n",
       "        [  5.2075,   3.6226,   8.8302,   3.2830,   7.8113,   6.6792,   5.2075,\n",
       "           8.8302,   8.3774,   8.3774],\n",
       "        [  2.5512,   3.8740,   6.4252,   4.2520,   3.4961,   6.9921,   2.9291,\n",
       "           7.5591,   6.5197,   7.9370],\n",
       "        [  0.0000,  -4.9091,  11.1818,  12.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "101d000c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1',\n",
       " '3',\n",
       " '3',\n",
       " '2',\n",
       " '3',\n",
       " '0',\n",
       " '3',\n",
       " '0',\n",
       " '0',\n",
       " '3',\n",
       " '2',\n",
       " '3',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '0',\n",
       " '3',\n",
       " '1',\n",
       " '0',\n",
       " '3',\n",
       " '3',\n",
       " '1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50b4e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(b):\n",
    "    return [int(float(x)//1) for x in b.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e5e3b97-531f-432b-943f-05799c0b8939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_transformed_image(a[6],get_args(b[6]),get_args(b[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef80c66a-6a07-483e-bdec-a80686fc1e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"CPU\")\n",
    "print(device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "536c49d2-e065-4508-8c1d-64e4d5da4754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PNet, self).__init__()\n",
    "\n",
    "        # 定义网络层\n",
    "        self.conv1 = nn.Conv2d(3, 10, 3)  #12 -> 10 -> maxp -> 5\n",
    "        self.conv2 = nn.Conv2d(10, 16, 3) #5 -> 3\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3) #3 -> 1\n",
    "\n",
    "        self.face_det = nn.Conv2d(32, 2, 1) #1 -> 1\n",
    "        self.bbox = nn.Conv2d(32, 10, 1) #1 -> 1\n",
    "        self.landmark = nn.Conv2d(32, 10, 1) #1 -> 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 定义前向传播\n",
    "        x = F.relu(self.conv1(x)) #10\n",
    "        x = F.max_pool2d(x, 2) #5\n",
    "        x = F.relu(self.conv2(x)) #3\n",
    "        x = F.relu(self.conv3(x)) #1\n",
    "\n",
    "        facedet = F.relu(self.face_det(x))\n",
    "        bbox = F.relu(self.bbox(x))\n",
    "        landmark = F.relu(self.landmark(x))\n",
    "\n",
    "        facedet = torch.flatten(facedet, 1)\n",
    "        bbox = torch.flatten(bbox, 1)\n",
    "        landmark = torch.flatten(landmark, 1)\n",
    "\n",
    "        return facedet, bbox, landmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70b65901-3e1b-4723-b40a-3ad7f1753954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PNetLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PNetLoss, self).__init__()\n",
    "        # 初始化可以在这里完成，如果有必要的话\n",
    "\n",
    "    def forward(self, facedet, bbox, landmark, label, ltypes):\n",
    "        # 假设 'device' 是一个全局变量或已经事先定义好的\n",
    "        loss_total = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "        \n",
    "        for i, ltype in enumerate(ltypes):\n",
    "            # 计算面部检测损失\n",
    "            facedet_loss = torch.pow(facedet[i][0] - 1, 2)\n",
    "            \n",
    "            if ltype == \"2\":\n",
    "                # 对于类型2，只需要面部检测损失\n",
    "                loss_total = loss_total + facedet_loss\n",
    "            elif ltype in [\"1\", \"0\"]:\n",
    "                # 对于类型1和0，计算边界框损失\n",
    "                bbox_loss = F.mse_loss(bbox[i], label[i])\n",
    "                loss_total = loss_total + (bbox_loss + facedet_loss)\n",
    "            elif ltype == \"3\":\n",
    "                # 对于类型3，计算关键点损失\n",
    "                landmark_loss = F.mse_loss(landmark[i], label[i])\n",
    "                loss_total = loss_total + (landmark_loss + facedet_loss)\n",
    "\n",
    "        return loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d908743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x263db32b090>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a306c4ac-24ba-43a4-a46c-e60ac3615d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNet(\n",
      "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (face_det): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bbox): Conv2d(32, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (landmark): Conv2d(32, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "1 683.6535034179688 683.6535034179688 32 130000\n",
      "2 617.8057861328125 650.7296447753906 64 130000\n",
      "3 684.5799560546875 662.0130818684896 96 130000\n",
      "4 795.099609375 695.2847137451172 128 130000\n",
      "5 679.6245727539062 692.152685546875 160 130000\n",
      "6 625.7022705078125 681.0776163736979 192 130000\n",
      "7 866.8304443359375 707.6137346540179 224 130000\n",
      "8 801.1862182617188 719.3102951049805 256 130000\n",
      "9 600.3334350585938 706.0906439887153 288 130000\n",
      "10 498.264892578125 685.3080688476563 320 130000\n",
      "11 738.489013671875 690.1427001953125 352 130000\n",
      "12 795.678955078125 698.9373881022135 384 130000\n",
      "13 716.2138671875 700.266348031851 416 130000\n",
      "14 554.2288208007812 689.8350960867746 448 130000\n",
      "15 772.3038330078125 695.3330118815104 480 130000\n",
      "16 781.8153686523438 700.7381591796875 512 130000\n",
      "17 817.2306518554688 707.5906587488511 544 130000\n",
      "18 799.4329833984375 712.6930101182726 576 130000\n",
      "19 692.8926391601562 711.6508853310033 608 130000\n",
      "20 795.4197387695312 715.8393280029297 640 130000\n",
      "21 665.9539794921875 713.4638352167038 672 130000\n",
      "22 757.7755737304688 715.4780051491477 704 130000\n",
      "23 739.4248046875 716.5191703464674 736 130000\n",
      "24 662.2849731445312 714.2594121297201 768 130000\n",
      "25 645.467041015625 711.5077172851562 800 130000\n",
      "26 602.9174194335938 707.3311673677885 832 130000\n",
      "27 671.1024780273438 705.9893640588831 864 130000\n",
      "28 705.8366088867188 705.98390851702 896 130000\n",
      "29 503.6627502441406 699.0073168524381 928 130000\n",
      "30 688.800537109375 698.6670908610026 960 130000\n",
      "31 666.4519653320312 697.6278932632938 992 130000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(facedet, bbox, landmark, label, ltypes)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 反向传播和优化\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 反向传播计算当前的梯度\u001b[39;00m\n\u001b[0;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# 更新参数\u001b[39;00m\n\u001b[0;32m     32\u001b[0m train_loss_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\lucyc\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucyc\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = PNet()\n",
    "print(model)\n",
    "\n",
    "model.to(device)  # 将模型发送到GPU，如果有的话\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = PNetLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "\n",
    "    train_loss_acc = 0.\n",
    "    train_num = 0\n",
    "\n",
    "    for inputs in train_loader:\n",
    "        \n",
    "        img_tensor = inputs[0].to(device)\n",
    "        label = inputs[1].to(device)\n",
    "        ltypes = inputs[2]\n",
    "\n",
    "        facedet, bbox, landmark = model(img_tensor)\n",
    "        optimizer.zero_grad()  # 清除之前的梯度\n",
    "        loss = criterion(facedet, bbox, landmark, label, ltypes)\n",
    "        # 反向传播和优化\n",
    "        loss.backward()  # 反向传播计算当前的梯度\n",
    "        optimizer.step()  # 更新参数\n",
    "\n",
    "        train_loss_acc += loss.item()\n",
    "        train_num += 1\n",
    "\n",
    "        print(train_num,loss.item(),train_loss_acc/train_num, train_num*32, len(train_dataset))\n",
    "\n",
    "    model.eval() \n",
    "    val_loss_acc = 0\n",
    "    val_num = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs in val_loader:\n",
    "            img_tensor = inputs[0].to(device)\n",
    "            label = inputs[1].to(device)\n",
    "            ltypes = inputs[2]\n",
    "\n",
    "            facedet, bbox, landmark = model(img_tensor)\n",
    "            optimizer.zero_grad()  # 清除之前的梯度\n",
    "            loss = criterion(facedet, bbox, landmark, label, ltypes)\n",
    "            # 反向传播和优化\n",
    "            loss.backward()  # 反向传播计算当前的梯度\n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "            val_loss_acc += loss.item()\n",
    "            val_num += 1\n",
    "\n",
    "            print(val_num,loss.item(),val_loss_acc/val_num, val_num*32, len(train_dataset))\n",
    "\n",
    "    print(\"Epoch [{}/{}], Loss: {:.2f}, Val_loss: {:.2f}\".format(epoch+1, num_epochs, val_loss_acc/val_num, val_loss_acc/val_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2d4f2-edd5-42f8-a50b-567ef8fa9506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e9758-d831-449b-a7e8-d16d0a7401a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3bcd23-51f9-4dd3-a6fd-00a0f1cd4e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed60163-fe48-4580-af24-e666a0760a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9fd2f3-70ae-4f83-a85b-616c48a64ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c7cb2d-0b76-435c-bc1a-e564fe988ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
